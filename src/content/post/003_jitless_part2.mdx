---
title: "AOT Inline Caches in SpiderMonkey"
publishDate: 2026-02-12
description: "Extending our AOT Infrastructure to Inline Cache Stubs"
tags: ["cpp", "jit", "spidermonkey"]
---

This is part two of boostrapping SpiderMonkeys JIT code into AOT code.
[Last time]() we introduced our approach for deterministic JIT code,
starting with the [baseline interpreter](), which involved patching
pointers and indirection. This time we will motivate extending this
infrastrucutre to capture and provide statistically likely code AOT.
Our primary target is a corpus of Inline Cache (IC) stubs.


## Inline Cache Stubs

Several great explainations of IC stubs already exist [on the
internet](). For completion sake, however, we'll briefly go into their
structure, emphasizing the SM idiosyncracies.


An IC is a bytecode local data structure comprised of two main
components. One, instrumentation of the interpreter to observe the
runtime type information flowing through an opcode. And two, a fast
native code stub for the opcode, specialized for the observed types.
For example, suppose we have a function like so:


```js
function blind_access_and_add(x, y) {
    return x.foo + y.foo;
}
```

Because JavaScript is dynamically typed, the bytecode produced from
this function includes several guards - runtime checks which ensure it
is legal to apply an operators in the given context. Guards make
JavaScript typesafe at runtime, but like any runtime solution, they
incur a perforance cost. Inline Cache stubs are an optimization which
cache the observed operand types for the operation and use them like
keys to dispatch into a high-performance native "stub" specailzied for
the types.

A common first impression when learning about IC stubs is that they
must produce rather short JIT code. How many instructions could we
really be saving by eliding the interpretation of a generic add for a
specialized compiled version? For some operators in particular, like
`x.foo`, you may be suprised. JavaScript uses a [protoype chain]()
object model in which properties may be either in local slots or in
dynamic slots of parent objects. Unlike an inheritence model, where a
member variable from a top-level class will be allocated at some fixed
offset in an instance of a derived class, an object inheriting from a
prototype doesn't locally know whether it contains a field `.foo` .
This means we must pain-stakingly traverse up the prototype chain,
sometimes _just to find a propert doesn't exist.

When we great an IC stub for a property access like `y.foo`, it means
we have seen the type of `y` before, we know it has a property like
`foo`, _and_ it has some fixed offset from the base allocation, just
like in statically typed languages. To solidify our intuition that
creating an inline cache for property access is worthwhile, lets look
at the generic bytecode versus the compiled stub.


A heavily simplified version of the generic VM routnine for
[NativeGetPropertyInline](https://searchfox.org/firefox-main/rev/08a5a0de94770126c13dceb661fee2edbdff0329/js/src/vm/NativeObject.cpp#2322)
is found below. This is in the VM, meaning it gest compiled down to
static code, not JIT code. After dumping the corresponding assembly I
determined it too long to include in this post.

```js
NativeGetPropertyInline(...) {
    for (;;) {
      // Look up property in this object's own properties
      NativeLookupOwnPropertyInline(cx, pobj, id, &prop);

      if (prop.isFound()) {
          // If found, extract value from slot.
          return GetExistingProperty(cx, receiver, pobj, id, prop, vp);
      }

      // If not found we need to walk up the prototype chain.
      JSObject* proto = pobj->staticPrototype();

      if (!proto) {
          // End of chain means property doesn't exist.
          return GetNonexistentProperty(cx, id, nameLookup, vp);
      }
      pobj = &proto->as<NativeObject>();
      // Loop again
    }
}
```
Second, the IC stub for the same property access, consiting of a shape
guard (single pointer comparison) and a direct slot load at a static
offset. Despite the disparate naming schemes, both of these functions
handle property access, the former generically through the VM and the
later through an IC stub.


```js
//firefox/js/src/jit/CacheIR.cpp:929

template <IsCrossCompartment MaybeCrossCompartment = IsCrossCompartment::No>
static void EmitReadSlotResult(CacheIRWriter& writer, NativeObject* obj,
                               NativeObject* holder, PropertyInfo prop,
                               ObjOperandId objId) {
  MOZ_ASSERT(holder);

  ObjOperandId holderId =
      EmitReadSlotGuard<MaybeCrossCompartment>(writer, obj, holder, objId);

  MOZ_ASSERT(holderId.valid());
  EmitLoadSlotResult(writer, holderId, holder, prop);
}
```

## A Brief Benchmark

Using the reflective profiling tooling exposed by SM, it is super easy
to gain some rough performance insights into this code.


```js
function blind_access_and_add(x, y) {
    return x.foo + y.foo;
}

for (var i=0; i<10000; i++) {
    blind_access_and_add({foo: 4}, {foo: 7})
}
```


## Planning an AOT Mechanism

Most of this work was done by [Chase]()

With that in mind, we can see how an IC stub speeds up performance,
and why we might want to supply a corpus of statistically likely stubs
to be ready out of the box. Before we get there however, lets
understand the mechanisms for dispatching IC stubs.

TODO: Introduce the IC stub data class.

SpiderMonkey already had some infrasturcture in place for AOT stubs.
[Chris Fallin]() designed an AOT stub system for designed an AOT stub
system for

